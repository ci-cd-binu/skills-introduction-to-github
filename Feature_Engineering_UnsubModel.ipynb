{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DOPxxtBaLDRqCmOYGQ7m0jvMiibIcMZ3",
      "authorship_tag": "ABX9TyP3YrI+yMamQivLvqyuO3O1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ci-cd-binu/skills-introduction-to-github/blob/main/Feature_Engineering_UnsubModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o3757Ta87Gwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features to engineer for Unsub Model** from datsets around Email engagement data (opens, clicks, forwards, etc.) | \tCustomer demographics (age, gender, location, etc.)| AND Customer purchase history :\n",
        "\n",
        "1.   Recency of engagement (how recently the customer has opened or clicked on an email)\n",
        "2.  Frequency of engagement (how often the customer opens or clicks on emails)\n",
        "1.  Type of engagement (what types of emails the customer typically opens or clicks on)\n",
        "2.   Customer lifetime value (CLV)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O4Hvz6Rw7JeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_features(email_engagement_data, customer_demographics, purchase_history):\n",
        "  \"\"\"Generates features from synthetic datasets.\"\"\"\n",
        "\n",
        "  # Recency of engagement\n",
        "  email_engagement_data[\"Recency of Engagement\"] = (\n",
        "      datetime.today() - pd.to_datetime(email_engagement_data[\"Date and Time Sent\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "  ).dt.days\n",
        "\n",
        "  # Frequency of engagement\n",
        "  email_engagement_data[\"Frequency of Engagement\"] = email_engagement_data.groupby(\n",
        "    \"Email Address\"\n",
        "  )[\"Open Status\"].sum()\n",
        "\n",
        "  # Type of engagement\n",
        "  email_engagement_data[\"Type of Engagement\"] = np.where(\n",
        "    email_engagement_data[\"Click Status\"] == True, \"Clicked\", \"Opened\"\n",
        "  )\n",
        "\n",
        "  # Customer lifetime value (CLV)\n",
        "  customer_clv = purchase_history.groupby(\"Email Address\")[\"Price\"].sum()\n",
        "  email_engagement_data = email_engagement_data.merge(\n",
        "    customer_clv.to_frame(name=\"CLV\"), on=\"Email Address\"\n",
        "  )\n",
        "\n",
        "  return email_engagement_data\n",
        "\n",
        "email_engagement_data = pd.read_csv(r\"/content/drive/MyDrive/datasets/email_engagement_data.csv\")\n",
        "customer_demographics = pd.read_csv(r\"/content/drive/MyDrive/datasets/customer_demographics.csv\")\n",
        "purchase_history = pd.read_csv(r\"/content/drive/MyDrive/datasets/purchase_history.csv\")\n",
        "\n",
        "featured_data = generate_features(email_engagement_data, customer_demographics, purchase_history)\n",
        "\n",
        "#print(featured_data.to_string())\n",
        "print(featured_data.head(5).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9qWeHNx8V4E",
        "outputId": "04168b86-8661-43a5-d9e2-d9ea811ce0a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Email Address          Date and Time Sent    Subject Line  Open Status  Click Status  Forward Status  Recency of Engagement  Frequency of Engagement Type of Engagement   CLV\n",
            "0  user0@example.com  2023-10-21 10:26:27.958802  Subject Line 0         True          True           False                      0                      NaN            Clicked  40.0\n",
            "1  user1@example.com  2023-10-20 10:26:27.958815  Subject Line 1        False         False            True                      1                      NaN             Opened  20.0\n",
            "2  user2@example.com  2023-10-19 10:26:27.958818  Subject Line 2         True         False           False                      2                      NaN             Opened  40.0\n",
            "3  user3@example.com  2023-10-18 10:26:27.958820  Subject Line 3         True         False           False                      3                      NaN             Opened  20.0\n",
            "4  user4@example.com  2023-10-17 10:26:27.958821  Subject Line 4         True         False           False                      4                      NaN             Opened  20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate CLV based on customer lifetime value models\n",
        "!pip install lifetimes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeYnVf1lRubf",
        "outputId": "57a46c2c-f1e4-4b47-ad18-b85903630829"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifetimes in /usr/local/lib/python3.10/dist-packages (0.11.3)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from lifetimes) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifetimes) (1.11.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from lifetimes) (1.5.3)\n",
            "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifetimes) (1.6.2)\n",
            "Requirement already satisfied: dill>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from lifetimes) (0.3.7)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->lifetimes) (0.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->lifetimes) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->lifetimes) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->lifetimes) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lifetimes import BetaGeoFitter, GammaGammaFitter"
      ],
      "metadata": {
        "id": "8UfQjb0UUID0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_clv(purchase_history):\n",
        "    # Calculate basic RFM values\n",
        "    today = datetime.today()\n",
        "    rfm = purchase_history.groupby('Email Address').agg({\n",
        "        'Purchase Date': [lambda date: (today - pd.to_datetime(date).max()).days,\n",
        "                          lambda date: (today - pd.to_datetime(date).min()).days],\n",
        "        'Price': ['count', 'sum']\n",
        "    }).reset_index()\n",
        "    rfm.columns = ['Email Address', 'Recency', 'T', 'Frequency', 'Monetary_Value']\n",
        "\n",
        "    # For BG/NBD, the Frequency represents the number of repeat (not total) transactions.\n",
        "    rfm['Frequency'] = rfm['Frequency'] - 1\n",
        "\n",
        "    # Fit the BG/NBD model\n",
        "    bgf = BetaGeoFitter(penalizer_coef=0.0)\n",
        "    bgf.fit(rfm['Recency'], rfm['Frequency'])\n",
        "\n",
        "    # Predict the customer's future transaction in next 10 days for example\n",
        "    rfm[\"predicted_purchases\"] = bgf.predict(10, rfm['Recency'], rfm['Frequency'])\n",
        "\n",
        "    # For monetary value, we use only those customers who had at least one repeat purchase with us.\n",
        "    returning_customers_summary = rfm[rfm['Frequency'] > 1]\n",
        "\n",
        "    # Fit the Gamma-Gamma model\n",
        "    ggf = GammaGammaFitter(penalizer_coef=0.0)\n",
        "    ggf.fit(returning_customers_summary['Frequency'],\n",
        "            returning_customers_summary['Monetary_Value'])\n",
        "\n",
        "    # Predict the customer's average transaction value in the next period\n",
        "    rfm[\"predicted_monetary_value\"] = ggf.predict(returning_customers_summary['Frequency'],\n",
        "                                                  returning_customers_summary['Monetary_Value'])\n",
        "\n",
        "    # Now, combine predicted_purchases and predicted_monetary_value to compute CLV\n",
        "    rfm[\"CLV\"] = rfm[\"predicted_purchases\"] * rfm[\"predicted_monetary_value\"]\n",
        "\n",
        "    return rfm[[\"CLV\"]]\n",
        "\n",
        "\n",
        "# Calculate CLV\n",
        "clv_data = calculate_clv(purchase_history)\n",
        "\n",
        "#print(featured_data.to_string())\n",
        "print(clv_data.head(5).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "NcAzXTc1UKCs",
        "outputId": "5af446fa-64f2-481b-e9c2-ee96bd276fd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3c1204543d89>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Calculate CLV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mclv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_clv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpurchase_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#print(featured_data.to_string())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3c1204543d89>\u001b[0m in \u001b[0;36mcalculate_clv\u001b[0;34m(purchase_history)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Calculate basic RFM values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     rfm = purchase_history.groupby('Email Address').agg({\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m'Purchase Date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'Order Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_dictlike_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mnormalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0mcols_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column(s) {cols_sorted} do not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0maggregator_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['Order Id'] do not exist\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from lifetimes import BetaGeoNBD\n",
        "\n",
        "def generate_features(email_engagement_data, customer_demographics, purchase_history):\n",
        "  \"\"\"Generates features from synthetic datasets.\"\"\"\n",
        "\n",
        "  # Recency of engagement\n",
        "  email_engagement_data[\"Recency of Engagement\"] = (\n",
        "      datetime.today() - pd.to_datetime(email_engagement_data[\"Date and Time Sent\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "  ).dt.days\n",
        "\n",
        "  # Frequency of engagement\n",
        "  email_engagement_data[\"Frequency of Engagement\"] = email_engagement_data.groupby(\n",
        "    \"Email Address\"\n",
        "  )[\"Open Status\"].sum()\n",
        "\n",
        "  # Type of engagement\n",
        "  email_engagement_data[\"Type of Engagement\"] = np.where(\n",
        "    email_engagement_data[\"Click Status\"] == True, \"Clicked\", \"Opened\"\n",
        "  )\n",
        "\n",
        "  # Customer lifetime value (CLV)\n",
        "  customer_clv = purchase_history.groupby(\"Email Address\")[\"Price\"].sum()\n",
        "  email_engagement_data = email_engagement_data.merge(\n",
        "    customer_clv.to_frame(name=\"CLV\"), on=\"Email Address\"\n",
        "  )\n",
        "\n",
        "  # Email engagement data\n",
        "\n",
        "  # Number of emails sent to customer\n",
        "  email_engagement_data[\"Number of Emails Sent\"] = email_engagement_data.groupby(\"Email Address\")[\"Date and Time Sent\"].transform('size')\n",
        "\n",
        "  # Average open rate\n",
        "  email_engagement_data[\"Average Open Rate\"] = email_engagement_data.groupby(\"Email Address\")[\"Open Status\"].mean()\n",
        "\n",
        "  # Average click rate\n",
        "  email_engagement_data[\"Average Click Rate\"] = email_engagement_data.groupby(\"Email Address\")[\"Click Status\"].mean()\n",
        "\n",
        "  # Customer demographics\n",
        "\n",
        "  # Age group\n",
        "  email_engagement_data[\"Age Group\"] = pd.cut(customer_demographics[\"Age Group\"], bins=[0, 18, 25, 35, 45, 55, 65, np.inf])\n",
        "\n",
        "  # Gender\n",
        "  email_engagement_data[\"Gender\"] = customer_demographics[\"Gender\"]\n",
        "\n",
        "  # Location\n",
        "  email_engagement_data[\"Location\"] = customer_demographics[\"Location\"]\n",
        "\n",
        "  # Purchase history\n",
        "\n",
        "  # Average order value\n",
        "  email_engagement_data[\"Average Order Value\"] = purchase_history.groupby(\"Email Address\")[\"Price\"].mean()\n",
        "\n",
        "  # Number of orders placed\n",
        "  email_engagement_data[\"Number of Orders Placed\"] = purchase_history.groupby(\"Email Address\")[\"Purchase Date\"].transform('size')\n",
        "\n",
        "  # Last purchase date\n",
        "  email_engagement_data[\"Last Purchase Date\"] = purchase_history.groupby(\"Email Address\")[\"Purchase Date\"].transform('max')\n",
        "\n",
        "  # RFM score\n",
        "  email_engagement_data = calculate_rfm_score(email_engagement_data)\n",
        "\n",
        "  # CLV based on BG/NBD model\n",
        "  email_engagement_data[\"CLV_BG/NBD\"] = calculate_clv_bg_nbd(purchase_history)\n",
        "\n",
        "  # CLV based on customer engagement\n",
        "  email_engagement_data[\"CLV_Engagement\"] = calculate_clv_engagement(email_engagement_data, purchase_history)\n",
        "\n",
        "  return email_engagement_data\n",
        "\n",
        "def calculate_rfm_score(featured_data):\n",
        "  \"\"\"Calculates RFM scores for customers.\"\"\"\n",
        "\n",
        "  # Recency\n",
        "  featured_data[\"Recency Score\"] = pd.qcut(featured_data[\"Recency of Engagement\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # Frequency\n",
        "  featured_data[\"Frequency Score\"] = pd.qcut(featured_data[\"Frequency of Engagement\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # Monetary value\n",
        "  featured_data[\"Monetary Value Score\"] = pd.qcut(featured_data[\"CLV\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # RFM score\n",
        "  featured_data[\"RFM Score\"] = featured_data[\"Recency Score\"] + featured_data[\"Frequency Score\"] + featured_data[\"Monetary Value Score\"]\n",
        "\n",
        "  return featured_data\n",
        "\n",
        "def calculate_clv_bg_nbd(purchase_history):\n",
        "  \"\"\"Calculates CLV based on the BG/NBD model.\"\"\"\n",
        "\n",
        "  bg_nbd = BetaGeoNBD(purchase_history)\n",
        "  bg_nbd.fit()\n",
        "\n",
        "  clv = bg_nb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "zNmZdImTPBin",
        "outputId": "3721243c-600a-4f4f-e34b-9c8694b44cdd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5e4a30ef63b9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlifetimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBetaGeoNBD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_engagement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_demographics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurchase_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BetaGeoNBD' from 'lifetimes' (/usr/local/lib/python3.10/dist-packages/lifetimes/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import lifetimes\n",
        "from lifetimes import BetaGeoNBD\n",
        "\n",
        "def generate_features(email_engagement_data, customer_demographics, purchase_history):\n",
        "  \"\"\"Generates features from synthetic datasets.\"\"\"\n",
        "\n",
        "  # Recency of engagement\n",
        "  email_engagement_data[\"Recency of Engagement\"] = (\n",
        "      datetime.today() - pd.to_datetime(email_engagement_data[\"Date and Time Sent\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "  ).dt.days\n",
        "\n",
        "  # Frequency of engagement\n",
        "  email_engagement_data[\"Frequency of Engagement\"] = email_engagement_data.groupby(\n",
        "    \"Email Address\"\n",
        "  )[\"Open Status\"].sum()\n",
        "\n",
        "  # Type of engagement\n",
        "  email_engagement_data[\"Type of Engagement\"] = np.where(\n",
        "    email_engagement_data[\"Click Status\"] == True, \"Clicked\", \"Opened\"\n",
        "  )\n",
        "\n",
        "  # Customer lifetime value (CLV)\n",
        "  customer_clv = purchase_history.groupby(\"Email Address\")[\"Price\"].sum()\n",
        "  email_engagement_data = email_engagement_data.merge(\n",
        "    customer_clv.to_frame(name=\"CLV\"), on=\"Email Address\"\n",
        "  )\n",
        "\n",
        "  # Email engagement data\n",
        "\n",
        "  # Number of emails sent to customer\n",
        "  email_engagement_data[\"Number of Emails Sent\"] = email_engagement_data.groupby(\"Email Address\")[\"Date and Time Sent\"].transform('size')\n",
        "\n",
        "  # Average open rate\n",
        "  email_engagement_data[\"Average Open Rate\"] = email_engagement_data.groupby(\"Email Address\")[\"Open Status\"].mean()\n",
        "\n",
        "  # Average click rate\n",
        "  email_engagement_data[\"Average Click Rate\"] = email_engagement_data.groupby(\"Email Address\")[\"Click Status\"].mean()\n",
        "\n",
        "  # Customer demographics\n",
        "\n",
        "  # Age group\n",
        "  email_engagement_data[\"Age Group\"] = pd.cut(customer_demographics[\"Age Group\"], bins=[0, 18, 25, 35, 45, 55, 65, np.inf])\n",
        "\n",
        "  # Gender\n",
        "  email_engagement_data[\"Gender\"] = customer_demographics[\"Gender\"]\n",
        "\n",
        "  # Location\n",
        "  email_engagement_data[\"Location\"] = customer_demographics[\"Location\"]\n",
        "\n",
        "  # Purchase history\n",
        "\n",
        "  # Average order value\n",
        "  email_engagement_data[\"Average Order Value\"] = purchase_history.groupby(\"Email Address\")[\"Price\"].mean()\n",
        "\n",
        "  # Number of orders placed\n",
        "  email_engagement_data[\"Number of Orders Placed\"] = purchase_history.groupby(\"Email Address\")[\"Purchase Date\"].transform('size')\n",
        "\n",
        "  # Last purchase date\n",
        "  email_engagement_data[\"Last Purchase Date\"] = purchase_history.groupby(\"Email Address\")[\"Purchase Date\"].transform('max')\n",
        "\n",
        "  # RFM score\n",
        "  email_engagement_data = calculate_rfm_score(email_engagement_data)\n",
        "\n",
        "  # CLV based on BG/NBD model\n",
        "  email_engagement_data[\"CLV_BG/NBD\"] = calculate_clv_bg_nbd(purchase_history)\n",
        "\n",
        "  # CLV based on customer engagement\n",
        "  email_engagement_data[\"CLV_Engagement\"] = calculate_clv_engagement(email_engagement_data, purchase_history)\n",
        "\n",
        "  return email_engagement_data\n",
        "\n",
        "def calculate_rfm_score(featured_data):\n",
        "  \"\"\"Calculates RFM scores for customers.\"\"\"\n",
        "\n",
        "  # Recency\n",
        "  featured_data[\"Recency Score\"] = pd.qcut(featured_data[\"Recency of Engagement\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # Frequency\n",
        "  featured_data[\"Frequency Score\"] = pd.qcut(featured_data[\"Frequency of Engagement\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # Monetary value\n",
        "  featured_data[\"Monetary Value Score\"] = pd.qcut(featured_data[\"CLV\"], 5, labels=[5, 4, 3, 2, 1])\n",
        "\n",
        "  # RFM score\n",
        "  featured_data[\"RFM Score\"] = featured_data[\"Recency Score\"] + featured_data[\"Frequency Score\"] + featured_data[\"Monetary Value Score\"]\n",
        "\n",
        "  return featured_data\n",
        "\n",
        "def calculate_clv_bg_nbd(purchase_history):\n",
        "  \"\"\"Calculates CLV based on the BG/NBD model.\"\"\"\n",
        "\n",
        "  bg_nbd = BetaGeoNBD(purchase_history)\n",
        "  bg_nbd.fit()\n",
        "\n",
        "  clv =\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Fv8-6szUSyd9",
        "outputId": "0d9b73f2-5feb-4b86-bb7f-dca593e14330"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4da36160c79b>\"\u001b[0;36m, line \u001b[0;32m98\u001b[0m\n\u001b[0;31m    clv =\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Anl78iWERnJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-4\n"
      ],
      "metadata": {
        "id": "gbmTi2HGW1Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from lifetimes import BetaGeoFitter, GammaGammaFitter\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_features(email_engagement_data, customer_demographics, purchase_history):\n",
        "    \"\"\"Generates features for predicting email unsubscriptions.\"\"\"\n",
        "\n",
        "    # Recency of engagement\n",
        "    email_engagement_data[\"Recency of Engagement\"] = (\n",
        "        datetime.today() - pd.to_datetime(email_engagement_data[\"Date and Time Sent\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "    ).dt.days\n",
        "\n",
        "    # Frequency of engagement\n",
        "    email_engagement_data[\"Frequency of Engagement\"] = email_engagement_data.groupby(\n",
        "        \"Email Address\"\n",
        "    )[\"Open Status\"].transform('sum')\n",
        "\n",
        "    # Type of engagement\n",
        "    email_engagement_data[\"Type of Engagement\"] = np.where(\n",
        "        email_engagement_data[\"Click Status\"] == True, \"Clicked\", \"Opened\"\n",
        "    )\n",
        "\n",
        "    # Merging datasets\n",
        "    data = email_engagement_data.merge(\n",
        "        customer_demographics, on=\"Email Address\", how=\"left\"\n",
        "    ).merge(\n",
        "        purchase_history.groupby(\"Email Address\").agg(Total_Spent=pd.NamedAgg(column=\"Price\", aggfunc=\"sum\"),\n",
        "                                                     Purchase_Count=pd.NamedAgg(column=\"Purchase Date\", aggfunc=\"size\"),\n",
        "                                                     Avg_Purchase_Value=pd.NamedAgg(column=\"Price\", aggfunc=\"mean\")),\n",
        "        on=\"Email Address\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Customer lifetime value (CLV)\n",
        "    data[\"CLV\"] = data[\"Total_Spent\"]\n",
        "\n",
        "    # Add additional CLV based on BG/NBD model\n",
        "    rfm = purchase_history.groupby('Email Address').agg({\n",
        "        'Purchase Date': [lambda date: (datetime.today() - pd.to_datetime(date).max()).days],\n",
        "        'Price': ['count', 'sum']\n",
        "    }).reset_index()\n",
        "    rfm.columns = ['Email Address', 'Recency', 'Frequency', 'Monetary_Value']\n",
        "    rfm['Frequency'] = rfm['Frequency'] - 1\n",
        "    bgf = BetaGeoFitter(penalizer_coef=0.0)\n",
        "    bgf.fit(rfm['Recency'], rfm['Frequency'])\n",
        "    predicted_purchases = bgf.predict(365, rfm['Recency'], rfm['Frequency'])\n",
        "    ggf = GammaGammaFitter(penalizer_coef=0.0)\n",
        "    ggf.fit(rfm['Frequency'], rfm['Monetary_Value'])\n",
        "    predicted_monetary_value = ggf.predict(rfm['Frequency'], rfm['Monetary_Value'])\n",
        "    rfm[\"CLV_BG/NBD\"] = predicted_purchases * predicted_monetary_value\n",
        "    data = data.merge(rfm[[\"Email Address\", \"CLV_BG/NBD\"]], on=\"Email Address\", how=\"left\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "email_engagement_data = pd.read_csv(r\"/content/drive/MyDrive/datasets/email_engagement_data.csv\")\n",
        "customer_demographics = pd.read_csv(r\"/content/drive/MyDrive/datasets/customer_demographics.csv\")\n",
        "purchase_history = pd.read_csv(r\"/content/drive/MyDrive/datasets/purchase_history.csv\")\n",
        "featured_data = generate_features(email_engagement_data, customer_demographics, purchase_history)\n",
        "\n",
        "print(featured_data.head(5).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "m8yWM4gFW3bn",
        "outputId": "e1c23ef3-09e5-41c7-f5f3-453d20c1d824"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-218ba49738f6>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mcustomer_demographics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/drive/MyDrive/datasets/customer_demographics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mpurchase_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/drive/MyDrive/datasets/purchase_history.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mfeatured_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_engagement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_demographics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurchase_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatured_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-218ba49738f6>\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(email_engagement_data, customer_demographics, purchase_history)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Merging datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     data = email_engagement_data.merge(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mcustomer_demographics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Email Address\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10091\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10093\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10094\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10095\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 110\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             )\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Email Address'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from lifetimes import BetaGeoFitter, GammaGammaFitter\n",
        "\n",
        "def generate_features(email_engagement_data, customer_demographics, purchase_history):\n",
        "    \"\"\"Generates features from synthetic datasets.\"\"\"\n",
        "\n",
        "    # Recency of engagement\n",
        "    email_engagement_data[\"Recency of Engagement\"] = (\n",
        "        datetime.today() - pd.to_datetime(email_engagement_data[\"Date and Time Sent\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "    ).dt.days\n",
        "\n",
        "    # Frequency of engagement\n",
        "    email_engagement_data[\"Frequency of Engagement\"] = email_engagement_data.groupby(\n",
        "        \"Email Address\"\n",
        "    )[\"Open Status\"].transform('sum')\n",
        "\n",
        "    # Type of engagement\n",
        "    email_engagement_data[\"Type of Engagement\"] = np.where(\n",
        "        email_engagement_data[\"Click Status\"] == True, \"Clicked\", \"Opened\"\n",
        "    )\n",
        "\n",
        "    # Basic Customer lifetime value (CLV)\n",
        "    customer_clv = purchase_history.groupby(\"Email Address\")[\"Price\"].sum()\n",
        "    email_engagement_data = email_engagement_data.merge(\n",
        "        customer_clv.to_frame(name=\"CLV\"), on=\"Email Address\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Additional CLV based on BG/NBD model\n",
        "    rfm = purchase_history.groupby('Email Address').agg({\n",
        "        'Purchase Date': [lambda date: (datetime.today() - pd.to_datetime(date).max()).days],\n",
        "        'Price': ['count', 'sum']\n",
        "    }).reset_index()\n",
        "    rfm.columns = ['Email Address', 'Recency', 'Frequency', 'Monetary_Value']\n",
        "    rfm['Frequency'] = rfm['Frequency'] - 1\n",
        "\n",
        "    # Ensure that Recency is 0 for all customers with a Frequency of 0\n",
        "    rfm.loc[rfm['Frequency'] == 0, 'Recency'] = 0\n",
        "\n",
        "    # Compute T for each customer\n",
        "    rfm['T'] = (datetime.today() - pd.to_datetime(purchase_history.groupby('Email Address')['Purchase Date'].min())).dt.days\n",
        "\n",
        "    #bgf = BetaGeoFitter(penalizer_coef=0.0)\n",
        "    bgf = BetaGeoFitter(penalizer_coef=0.01, maxiter=1000)\n",
        "    bgf.fit(rfm['Frequency'], rfm['Recency'], rfm['T'])\n",
        "\n",
        "    predicted_purchases = bgf.predict(365, rfm['Recency'], rfm['Frequency'])\n",
        "\n",
        "    ggf = GammaGammaFitter(penalizer_coef=0.0)\n",
        "    ggf.fit(rfm['Frequency'], rfm['Monetary_Value'])\n",
        "    predicted_monetary_value = ggf.predict(rfm['Frequency'], rfm['Monetary_Value'])\n",
        "\n",
        "    rfm[\"CLV_BG/NBD\"] = predicted_purchases * predicted_monetary_value\n",
        "    email_engagement_data = email_engagement_data.merge(rfm[[\"Email Address\", \"CLV_BG/NBD\"]], on=\"Email Address\", how=\"left\")\n",
        "\n",
        "    return email_engagement_data\n",
        "\n",
        "# Reading datasets\n",
        "email_engagement_data = pd.read_csv(r\"/content/drive/MyDrive/datasets/email_engagement_data.csv\")\n",
        "customer_demographics = pd.read_csv(r\"/content/drive/MyDrive/datasets/customer_demographics.csv\")\n",
        "purchase_history = pd.read_csv(r\"/content/drive/MyDrive/datasets/purchase_history.csv\")\n",
        "\n",
        "# Generating features\n",
        "featured_data = generate_features(email_engagement_data, customer_demographics, purchase_history)\n",
        "\n",
        "# Printing the result\n",
        "print(featured_data.head(5).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "yp6mMHVWYb29",
        "outputId": "9f22507d-a1b6-41ad-acbb-f57c6e7068e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4a67dbe2a650>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Generating features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mfeatured_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_engagement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomer_demographics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurchase_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Printing the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-4a67dbe2a650>\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(email_engagement_data, customer_demographics, purchase_history)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#bgf = BetaGeoFitter(penalizer_coef=0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbgf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBetaGeoFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalizer_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mbgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BetaGeoFitter.__init__() got an unexpected keyword argument 'maxiter'"
          ]
        }
      ]
    }
  ]
}